## 改进代理式 AI 工作流程组件的方法与模型选择技巧

在跑了评估，找到问题后，就要开始着手修改了。本节介绍的正是如何改善系统中不同组件的效果。

对于非 LLM 组件，比如网页搜索、RAG 检索、代码执行、传统 ML 模型来说，改进方式非常多样。

* 调整参数或超参数：
  * 网页搜索： 调整结果数量、日期范围等。
  * RAG 检索： 更改相似度阈值、文本分块大小等。
  * 人物检测： 调整检测阈值，以权衡误报和漏报。
* 替换组件： 尝试更换不同的服务提供商，如不同的 RAG 搜索引擎、不同的 Web 搜索 API找到最适合系统的一个。按笔者经验，在国内查询企业营收报表和财务信息，使用百度搜索的效果就远超Bing或Google，但查询学术资源却完全相反。

对于LLM 组件，改进主要围绕输入、模型本身和工作流程结构展开。

* 改进提示词：增加明确指令（在提示词中指明一些资源和任务应有的规划路径，而不是让LLM自己猜）；使用少样本提示 (添加具体的输入和期望输出示例)
* 尝试不同的 LLM： 不要嫌麻烦，多测试几款 LLM，并使用评估 (Evals) 来选择最适合特定应用的最佳模型。
* 任务分解：如果单个步骤的指令过于复杂，导致 LLM 难以准确执行，考虑将任务分解为更小的、更易于管理的步骤，比如拆成生成步骤 + 反思步骤，或连续多次调用。
* 微调模型：这是最复杂、成本最高的选项。只有在穷尽所有其他方法后，仍需要挤出最后几个百分点的性能改进时才考虑。它适用于更成熟且性能要求极高的应用。

如果你之前也做过类似工作，那你一定拥有一定程度的模型选择直觉

> 比如笔者对于当前时间节点（2025年11月初）的模型，就认为Qwen比较嘴硬，Gemini2.5比较逆来顺受，GPT比较言简意赅，DeepSeek比较有创意和鬼点子。不同模型擅长的领域也不一样，比如Gemini对一口气生成上千行代码非常在行，而Claude对在现有系统里做小范围修改更有心得。如果谈到具体任务，那么嘴硬的Qwen就更适合用作一些比较严谨的，比如数据报表查询场景。又比如非常有逻辑但容易过度自信的KimiK2，就能在中低难度场景以简短而有信服力的输出大放异彩，但在比较复杂的场景要做好它过于自信而出错的心理准备。
>
> 在模型层面以外，还有其他类型的直觉，比如在笔者感受中，大参数模型通常比小参数模型的情商更高，对模糊指令的理解能力更强。最典型的例子是今年年初发布的昂贵的GPT-4.5，甚至可以在时下流行的“山东饭局”风格高情商场景下讲出让人眼前一亮的回复。
>
> 又比如，新架构+大参数量的模型，一般在多步骤复杂指令的任务中，能够完美地列出并编辑所有敏感信息，而较小的模型容易出错或遗漏信息。

拥有对不同 LLM 能力的直觉，能使开发者更高效地选择模型和编写提示词。这样的直觉要如何培养？

1. 频繁试玩不同模型： 经常测试新的闭源和开源模型，观察它们在不同查询上的表现。

> 笔者对自己的要求是，至少有3~5种主力使用的模型（同一提供商只计算一次），并保持一个月内至少使用过10种以上模型，并能报出20种以上模型的型号。

2. 建立个人评估集： 使用一套固定的评估任务来校准不同模型的能力。
3. 阅读他人的提示词： 大量阅读从业者、专家或开源框架中的提示词，了解不同任务/模型/场景下的最佳实践，提高自己编写提示词的能力。
4. 在工作流程中尝试： 实际在Agent工作流程中尝试不同的模型，查看追踪 (Traces) 和组件/端到端评估，观察它们在特定任务中的性能、价格和速度的权衡。